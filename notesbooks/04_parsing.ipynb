{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ModelMetaclass' from 'pydantic.main' (/home/brian/github/three-body-problem/.venv/lib/python3.10/site-packages/pydantic/main.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mspacy\u001b[39;00m \u001b[39mimport\u001b[39;00m displacy\n\u001b[1;32m      4\u001b[0m \u001b[39m# load language model\u001b[39;00m\n",
      "File \u001b[0;32m~/github/three-body-problem/.venv/lib/python3.10/site-packages/spacy/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[1;32m      5\u001b[0m \u001b[39m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39merrors\u001b[39;00m \u001b[39mimport\u001b[39;00m setup_default_warnings\n\u001b[1;32m      8\u001b[0m setup_default_warnings()  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[0;32m~/github/three-body-problem/.venv/lib/python3.10/site-packages/spacy/errors.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m Literal\n\u001b[1;32m      6\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mErrorsWithCodes\u001b[39;00m(\u001b[39mtype\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, code):\n",
      "File \u001b[0;32m~/github/three-body-problem/.venv/lib/python3.10/site-packages/spacy/compat.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"Helpers for Python and platform compatibility.\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mthinc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m copy_array\n\u001b[1;32m      6\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mcPickle\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n",
      "File \u001b[0;32m~/github/three-body-problem/.venv/lib/python3.10/site-packages/thinc/__init__.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mabout\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m registry\n\u001b[1;32m      8\u001b[0m \u001b[39m# fmt: off\u001b[39;00m\n\u001b[1;32m      9\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mregistry\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m__version__\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m ]\n",
      "File \u001b[0;32m~/github/three-body-problem/.venv/lib/python3.10/site-packages/thinc/config.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcatalogue\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mconfection\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconfection\u001b[39;00m \u001b[39mimport\u001b[39;00m Config, ConfigValidationError, Promise, VARIABLE_RE\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m Decorator\n",
      "File \u001b[0;32m~/github/three-body-problem/.venv/lib/python3.10/site-packages/confection/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel, create_model, ValidationError, Extra\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmain\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelMetaclass\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfields\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelField\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msrsly\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ModelMetaclass' from 'pydantic.main' (/home/brian/github/three-body-problem/.venv/lib/python3.10/site-packages/pydantic/main.py)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "# load language model\n",
    "zh_parser = spacy.load('zh_core_web_lg')## disable=[\"parser\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/cedict_ts.u8\", \"r+\") as f, open(\"../data/cedict_ts_reduced.u8\", \"w+\") as f2:\n",
    "    for line in f.readlines():\n",
    "        if (\"/variant of\" not in line) and (\"/(bound\" not in line):\n",
    "            f2.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cedict_utils.cedict import CedictParser\n",
    "parser = CedictParser()\n",
    "parser.read_file(\"../data/cedict_ts_reduced.u8\")\n",
    "entries = parser.parse()\n",
    "\n",
    "simple_dict = {x.simplified: {'meaning': x.meanings, 'pinyin': x.pinyin} for x in entries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_dict(book_path):\n",
    "\n",
    "    with open(f\"../data/books/{book_path}/book_data.json\", \"r+\") as f:\n",
    "        book_dict = json.loads(f.read())\n",
    "\n",
    "    return book_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get character frequency values from here... define a function and call it below\n",
    "# read in both csv files and write their rows to dictionaries\n",
    "import csv\n",
    "\n",
    "def csv_to_dict(filepath):\n",
    "    d = {}\n",
    "    with open(filepath, \"r\") as f:\n",
    "        csv_file = csv.reader(f)\n",
    "        for row in csv_file:\n",
    "            if row[0] == \"rank\": continue\n",
    "            d[row[1]] = row[0]\n",
    "    return d\n",
    "\n",
    "overall_ranks = csv_to_dict(\"../most_common_characters_corrected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency(c):\n",
    "    total_characters = 5000\n",
    "    rank = overall_ranks.get(c)\n",
    "    return int(rank)/total_characters if rank else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frequency(\"æ˜¯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a paragraph text string and parse it using spacy\n",
    "\n",
    "\n",
    "def parse_paragraph(p):\n",
    "    doc = zh_parser(p)\n",
    "    parsed_tokens = []\n",
    "    for token in doc:\n",
    "\n",
    "        # get character data\n",
    "        parsed_characters = []\n",
    "\n",
    "        characters = [x for x in token.text]\n",
    "        for character in characters:\n",
    "\n",
    "            character_definition = None\n",
    "            character_pinyin = None\n",
    "            if simple_dict.get(character):\n",
    "                character_definition = simple_dict.get(character).get(\"meaning\")\n",
    "                character_pinyin = simple_dict.get(character).get(\"pinyin\")\n",
    "\n",
    "            parsed_character = {\n",
    "                \"character\": character,\n",
    "                \"definition\": character_definition,\n",
    "                # \"occurances\": 0,\n",
    "                \"overall_frequency\": get_frequency(character),\n",
    "                \"pinyin\": character_pinyin,\n",
    "            }\n",
    "\n",
    "            parsed_characters.append(parsed_character)\n",
    "\n",
    "        # get definition from the dictionary defined above\n",
    "        definition = None\n",
    "        pinyin = None\n",
    "        if simple_dict.get(token.text):\n",
    "            definition = simple_dict.get(token.text).get('meaning')\n",
    "            pinyin = simple_dict.get(token.text).get('pinyin')\n",
    "\n",
    "\n",
    "        # parsed token\n",
    "        parsed_token = {\n",
    "            \"text\": token.text,\n",
    "            \"definition\": definition,\n",
    "            \"pinyin\": pinyin,\n",
    "            \"characters\": parsed_characters\n",
    "        }\n",
    "\n",
    "        parsed_tokens.append(parsed_token)\n",
    "    return parsed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book_dict = get_book_dict(\"dark_forest\")\n",
    "# p1 = book_dict.get(\"chapters\")[7].get(\"paragraphs\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_parsed_file_for_book(book_path, limit=None):\n",
    "    book_dict = get_book_dict(book_path)\n",
    "\n",
    "    for chapter in book_dict[\"chapters\"][:limit]:\n",
    "        print(chapter.get(\"title\"))\n",
    "        paragraphs = chapter.get(\"paragraphs\")\n",
    "\n",
    "        parsed_paragraphs = []\n",
    "        for i, p in enumerate(paragraphs):\n",
    "            parsed_paragraphs.append(parse_paragraph(p))\n",
    "        chapter[\"parsed_paragraphs\"] = parsed_paragraphs\n",
    "\n",
    "    with open(f\"../data/books/{book_path}/book_data_parsed.json\", \"w+\") as f:\n",
    "        json.dump(book_dict, f, ensure_ascii=False)\n",
    "\n",
    "    return book_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_parsed_file_for_book(\"three_body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_parsed_file_for_book(\"dark_forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_parsed_file_for_book(\"deaths_end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the end goal is to write a file called book_data_parsed.json\n",
    "import json\n",
    "with open(\"../data/books/three_body/book_data_parsed.json\", \"w+\") as f:\n",
    "    data = json.dump(book_dict, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/books/dark_forest/book_data_parsed.json\", \"r+\") as f:\n",
    "    read_object = json.loads(f.read())\n",
    "read_object"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
