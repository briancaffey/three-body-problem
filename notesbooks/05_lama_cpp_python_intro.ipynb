{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d98d8c-3595-44fe-a74f-b0055f90a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama, ChatCompletion, LlamaTokenizer, ChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e0bc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': 'You are an interpreter, please translate any prompt into English. 你是翻译者,请把输入的段子翻译成英文。'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': '在这段时间里，破壁人二号回顾了自己的一生，确定没有什么遗漏之后，翻动已经躺得麻木的身体，伸手从枕头下抽出手枪，缓缓把枪口凑到自己的太阳穴上。这时，他眼睛中出现了智子的字幕。',\n",
    "    }\n",
    "]\n",
    "\n",
    "MODEL = \"/home/brian/github/llama.cpp/models/7B/Chinese-Alpaca-2/ggml-model-q4_0.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61df2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ChatCompletion(model=MODEL, messages=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f11ba7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear\n",
      "copy\n",
      "fromkeys\n",
      "get\n",
      "items\n",
      "keys\n",
      "pop\n",
      "popitem\n",
      "setdefault\n",
      "update\n",
      "values\n"
     ]
    }
   ],
   "source": [
    "for item in dir(response): \n",
    "    if not item.startswith(\"__\"):\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5417a701-9290-4b57-942d-a88fda413076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/brian/github/llama.cpp/models/7B/Chinese-Alpaca-2/ggml-model-q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 55296\n",
      "llama_model_load_internal: n_ctx      = 4096\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 5504\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_head_kv  = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 1.0e-06\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.08 MB\n",
      "llama_model_load_internal: mem required  = 4299.79 MB (+ 2048.00 MB per state)\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n",
      "llama_new_context_with_model: kv self size  = 2048.00 MB\n"
     ]
    }
   ],
   "source": [
    "llm = Llama(model_path=\"/home/brian/github/llama.cpp/models/7B/Chinese-Alpaca-2/ggml-model-q4_0.bin\", seed=123, n_ctx=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eece68a-73ed-4751-802f-353a56605fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = LlamaTokenizer(llama=llm).encode(\"她点点头，“同意。昨天我在开心辞典节目上看到一个问题，巨傻：注意抢答——”她用叉子指着罗辑，学着那个女主持人的样子，“在末日前一百二十年，是你的第十三代，对还是不对？！”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0250a824-3311-441d-84f0-e0901bfdca76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 32008,\n",
       " 30940,\n",
       " 30940,\n",
       " 31584,\n",
       " 30214,\n",
       " 30015,\n",
       " 34200,\n",
       " 30267,\n",
       " 32848,\n",
       " 33442,\n",
       " 33780,\n",
       " 35494,\n",
       " 31259,\n",
       " 32992,\n",
       " 36911,\n",
       " 30780,\n",
       " 38209,\n",
       " 30214,\n",
       " 33804,\n",
       " 34211,\n",
       " 30383,\n",
       " 32610,\n",
       " 33008,\n",
       " 33069,\n",
       " 30003,\n",
       " 30003,\n",
       " 30024,\n",
       " 32008,\n",
       " 30406,\n",
       " 37774,\n",
       " 30319,\n",
       " 31084,\n",
       " 32011,\n",
       " 32171,\n",
       " 42678,\n",
       " 30214,\n",
       " 30415,\n",
       " 32011,\n",
       " 32380,\n",
       " 39565,\n",
       " 31695,\n",
       " 32764,\n",
       " 40322,\n",
       " 30214,\n",
       " 30015,\n",
       " 30505,\n",
       " 33068,\n",
       " 33586,\n",
       " 36962,\n",
       " 42882,\n",
       " 30214,\n",
       " 36394,\n",
       " 30210,\n",
       " 35804,\n",
       " 45773,\n",
       " 30214,\n",
       " 30783,\n",
       " 32014,\n",
       " 35000,\n",
       " 30882,\n",
       " 30584,\n",
       " 30024]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e089a6c-ea68-4450-bc0c-8a5a49684f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.n_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f255f4-170f-48d3-80c2-811a4e0bd1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
