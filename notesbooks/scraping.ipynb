{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook will scrape the HTML contents of the three body problem books from a website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "HEADERS = { 'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)' }\n",
    "BASE_URL = 'https://www.kunnu.com/santi/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "THREE_BODY_PAGE_IDS = [\n",
    "    85918,\n",
    "    85919,\n",
    "    26651,\n",
    "    26652,\n",
    "    26653,\n",
    "    26654,\n",
    "    26655,\n",
    "    26656,\n",
    "    26657,\n",
    "    26658,\n",
    "    26659,\n",
    "    26660,\n",
    "    26661,\n",
    "    26662,\n",
    "    26664,\n",
    "    26665,\n",
    "    26671,\n",
    "    26672,\n",
    "    26677,\n",
    "    26673,\n",
    "    26674,\n",
    "    26675,\n",
    "    26680,\n",
    "    26681,\n",
    "    26682,\n",
    "    26683,\n",
    "    26684,\n",
    "    26685,\n",
    "    26687,\n",
    "    26688,\n",
    "    26689,\n",
    "    26690,\n",
    "    26691,\n",
    "    26692,\n",
    "    26693,\n",
    "    26694,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DARK_FOREST_PAGE_IDS = [\n",
    "    26696,\n",
    "    26697,\n",
    "    26698,\n",
    "    26699,\n",
    "    26704,\n",
    "    26705,\n",
    "    26706,\n",
    "    26707,\n",
    "    26708,\n",
    "    26709,\n",
    "    26710,\n",
    "    26715,\n",
    "    26716,\n",
    "    26717,\n",
    "    26719,\n",
    "    26720,\n",
    "    26721,\n",
    "    26722,\n",
    "    26723,\n",
    "    26724,\n",
    "    26725,\n",
    "    26726,\n",
    "    83699,\n",
    "    26733,\n",
    "    26734,\n",
    "    26735,\n",
    "    26736,\n",
    "    26737,\n",
    "    26739,\n",
    "    26740,\n",
    "    26741,\n",
    "    26742,\n",
    "    26743,\n",
    "    26744,\n",
    "    26745,\n",
    "    26746,\n",
    "    26747,\n",
    "    26748,\n",
    "    26749,\n",
    "    26750,\n",
    "    26751,\n",
    "    26752,\n",
    "    26754,\n",
    "    26755,\n",
    "    26756,\n",
    "    26757,\n",
    "    26758,\n",
    "    26759,\n",
    "    85212,\n",
    "    85214,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEATHS_END_PAGE_IDS = [\n",
    "    85215,\n",
    "    26760,\n",
    "    26761,\n",
    "    26762,\n",
    "    26763,\n",
    "    26764,\n",
    "    26765,\n",
    "    26766,\n",
    "    26767,\n",
    "    26768,\n",
    "    26769,\n",
    "    26770,\n",
    "    26771,\n",
    "    26772,\n",
    "    26774,\n",
    "    26775,\n",
    "    26776,\n",
    "    26777,\n",
    "    26778,\n",
    "    26779,\n",
    "    26780,\n",
    "    26781,\n",
    "    85586,\n",
    "    26782,\n",
    "    26783,\n",
    "    26784,\n",
    "    85591,\n",
    "    26785,\n",
    "    26787,\n",
    "    26788,\n",
    "    85887,\n",
    "    26789,\n",
    "    26790,\n",
    "    26791,\n",
    "    26792,\n",
    "    26793,\n",
    "    85891,\n",
    "    85896,\n",
    "    85897,\n",
    "    26794,\n",
    "    26795,\n",
    "    26796,\n",
    "    85901,\n",
    "    26798,\n",
    "    26799,\n",
    "    26800,\n",
    "    26801,\n",
    "    26802,\n",
    "    85907,\n",
    "    26803,\n",
    "    26804,\n",
    "    85909,\n",
    "    26805,\n",
    "    85912,\n",
    "    85911,\n",
    "    26806,\n",
    "    26808,\n",
    "    85917,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_from_url(url):\n",
    "    print(f\"getting html for {url}\")\n",
    "    req = urllib.request.Request(url, headers=HEADERS)\n",
    "    response = urllib.request.urlopen(req)\n",
    "    page = response.read()\n",
    "\n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_chapters(book_name, page_ids):\n",
    "    for i, page_id in enumerate(page_ids):\n",
    "        url = f\"{BASE_URL}{page_id}.htm\"\n",
    "        print(f\"getting HTML for {url}\")\n",
    "        try:\n",
    "            html = get_html_from_url(url)\n",
    "            file_path = f\"../data/books/{book_name}/html/{i+1}_{page_id}.htm\"\n",
    "            print(file_path)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(html)\n",
    "        except urllib.error.HTTPError as e:\n",
    "            print(f\"not able to get text for URL, going to next URL\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_chapters('three_body', THREE_BODY_PAGE_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_chapters('dark_forest', DARK_FOREST_PAGE_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_chapters('deaths_end', DEATHS_END_PAGE_IDS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
